{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5449d69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify,render_template,url_for\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import json\n",
    "import random\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c532ddd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Restarting with watchdog (windowsapi)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Master\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3377: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('mental_chatbot_model.keras')\n",
    "\n",
    "# Load the words and classes\n",
    "words = pickle.load(open('words.pkl', 'rb'))\n",
    "classes = pickle.load(open('classes.pkl', 'rb'))\n",
    "\n",
    "# Load the intents file\n",
    "with open('mentalhealth.json', 'r') as json_data:\n",
    "    intents = json.load(json_data)\n",
    "\n",
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to clean up sentence\n",
    "def clean_up_sentence(sentence):\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "# Function to create bag of words\n",
    "def bow(sentence, words, show_details=True):\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    bag = [0]*len(words) \n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if w == s: \n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print (\"found in bag: %s\" % w)\n",
    "    return(np.array(bag))\n",
    "\n",
    "# Function to predict class/intent\n",
    "def predict_class(sentence, model):\n",
    "    ERROR_THRESHOLD = 0.25\n",
    "    p = bow(sentence, words, show_details=False)\n",
    "    res = model.predict(np.array([p]))[0]\n",
    "    results = [[i,r] for i,r in enumerate(res) if r>ERROR_THRESHOLD]\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
    "    return return_list\n",
    "\n",
    "# Function to get response\n",
    "def getResponse(ints, intents_json):\n",
    "    if ints:\n",
    "        tag = ints[0]['intent']\n",
    "        list_of_intents = intents_json['intents']\n",
    "        for i in list_of_intents:\n",
    "            if(i['tag']== tag):\n",
    "                result = random.choice(i['responses'])\n",
    "                break\n",
    "        return result\n",
    "    else:\n",
    "        return \"I'm sorry, I didn't understand that.\"\n",
    "\n",
    "# List of greetings and exit commands\n",
    "greetings = ['hi', 'hello', 'hey', 'good morning', 'good afternoon', 'good evening']\n",
    "exit_commands = [\"quit\", \"pause\", \"exit\", \"goodbye\", \"bye\", \"later\", \"stop\"]\n",
    "\n",
    "# Route for chatbot response\n",
    "@app.route('/chatbot', methods=['POST'])\n",
    "def chatbot_response():\n",
    "    user_input = request.json['message']\n",
    "    \n",
    "    if user_input.lower() in greetings:\n",
    "        return jsonify({'response': \"Hello! How can I assist you today?\"})\n",
    "    if user_input.lower() in exit_commands:\n",
    "        return jsonify({'response': \"Goodbye! Have a great day.\"})\n",
    "    \n",
    "    ints = predict_class(user_input, model)\n",
    "    res = getResponse(ints, intents)\n",
    "    return jsonify({'response': res})\n",
    "\n",
    "# Run the Flask app\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7f01d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3def85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
